# PA5: Sudoku
#Elias Rosenberg
#COSC 76
#21F
#Quattrini Li
#November 1, 2021

# Introduction: 
In this lab we were tasked with creating a boolean satisfiability solver, or SAT, that took in text files of sudoku boards broken down into conjunctive normal form values. Conjucjtive normal form is a way of structuring logic propositions. A CNF proposition is made up of different clauses, each of which is made up of variables that can be designated true or false. In this scenario, if any one of the variables in the clause was true, that entire clause was true (this is based on the 'or' operator). For an entire CNF phrase to be true, however, every claus within that phrase had to be true (based on the 'and' operator). More simply, you can think of variables in a clause follwing the structure 'if var1 is True, or var2 is True, or var3... then this claus is true .' For clauses it is 'if claus1 is true AND claus2 is true... then the whole CNF is satisfied.' To find assignments for the variables we needed to implement two SAT algorithms: GSAT and WalkSAT

#   (a) Description: How do your implemented algorithms work? What design decisions did you make? How you laid out the problems?
GSAT and WalkSAT work very similarly. Both take in a .cnf file that has variables assigned to every cell within a sudoku board. Each cell has many variables, that–when all satisfied with their clauses–yield one assignment for that cell. Let's take some values for the the cell at 1, 1. The first CNF claus in every file is [111, 112, 113, 114, 115, 116, 117, 118, 119]. This means that either cell at 1,1 holds a 1, or cell at 1,1 holds a 2... all the way up until 9. This makes sense, as if any one of these variables is true, then the cell at 1,1 must hold a number. If the value is negative, it equates to 'False'. -111 means cell 1,1 does NOT hold a 1. 

I, probably mistakenly, thought I was being clever with my implementation, but might need to go back and change everything. Instead of making lists with integers to show which variables were true or false, I made Variable and Clause classes. Each Variable takes a name that represents what it's called in the problem, and an 'assignmnent' that can be assigned to True or False. When going through the text file, I could split clauses by white space and assign each of those numbers to a Variable object. A Clause object also has an assignment which can be set to True or False, and holds a list of Variables. I thought it would be good to give myself this extra control over manipulating these crucial parts to the SAT with helper methods and more information about any given variable. But these algorithms store so much information and and take a very long time to assign values to variables, the way I implented these search problems takes up a huge amount of storage and time. I'll try to go back through and implement them in terms of simple primitives instead of classes, but I might not have time. My implementation does work! Running all_cells.cnf takes about 20 minutes. It is very, very slow. 

GSAT: I'll go through GSAT step by step because WalkSAT is largely based on GSAT. My GSAT takes max-flips and max-tries which equate to the amount of times we will try to flip variables within the clauses, and the amount of tries we will do to accomplish solving the sudoku puzzle. 
1) create a random 'model.' This means, we loop through all the variables in the problem and assign them randomly to True or False. 
2) If all the clauses in this model are already True, then we have a solution, so we can return it. 
3) If there are still clauses that evaluate to false, we go through every variable in the model, create a copy of the model, and flip that particular variable in the new model and store the model in a dictionary mapped to that variable's name. 
4) We then go through each new model in the dictionary, seeing which variable has caused the most False clauses to turn to True. 
5) We then use the model assigned to that variable back in step 2, and run the whole thing again. 

I have written many helper functions to do all of this. Finding the variable that affects the assignments of the most clauses is a little tricky. For that I used flip_variables() which creates the new models and stores them in a dictionary and returns it. Optimal_model() keeps track of how any clauses are satisfied in eacn model returned by the previous function, and then returns the model which now has the most True clauses to pump back into the algorithm. If things go right, we should keep building a CNF with more and more True assignments, and eventually every clause is True and we've solved it. 

Another crucial helper function I needed, due to my implementation, was rebuild_claus_assignments(). As an aside, I do know how to spell "clause," and recognize that I used "claus" throughout my entire code. I didn't realize I was doing it until my girlfriend pointed it out, and by then I thought it was too funnny/time consuming to go back and change everything. I was running into issues where the amount of True clauses wasn't changing when going through different models. I realized that, because I had assigned each clause it's boolean assignment when reading the text file, I was never changing how many True clauses each model actually had! This function simply went through the new model and re-assigned all the clauses to True based on their new, flipped variable. 

I had a similar problem with variable assignments when generating the new models. Because each variable was held in an bject, and because I did not know there was a difference between .copy() and .deepcopy(), every 'new_model' was the same as the original. After scouring the boolean values of many models, I noticed my mistake. After looking at the .copy() doccumentation, I learned that .copy() is a 'shallow' copy, in that it creates a new storage space in memory for the iterable itself, but only has reference pointers to the objects in the original. I needed a completely new list of clauses with new variables, so I now use .deepcopy() instead. That made the algorithm work, but now has added to a huge space-complexity issue that I will try to solve before tomorrow night.

WalkSAT: 

WalkSAT is basically the same as GSAT, but saves a huge amount of space by choosing random variables to flip within a False clause instead of flipping every single variable in the problem. It choses a random False clause and then, based on a probabilty given as a parameter, it can either 'take a walk' and find some random successors to pump back into the algorithm, or find the successors with the highest number of True clauses like in GSAT. This required a couple new helper functions to choose the list of new models, and few lines were changed within the GSAT algorithm. 

#   (b) Evaluation: Do your implemented algorithms actually work? How well? If it doesn’t work, can you tell why not? What partial successes did you have that deserve partial credit? 

The implemented algorithms work, albeit not that quickly. I got GSAT to work on one_cell.cnf and all_cells.cnf, but didn't have the time to sit and see if they worked on anything else. WalkSAT is much faster, and actually could solve the given Sudoku puzzles. The fact that the algorithms run so slowly is a monument to my hubris and lack of forsight. I had no idea there would be so much data to deal with. If I had realized before hand I never would have stored everything in objects. I remembered that helped me out a lot for the CSP lab, so I thought doing it again might be clever. It was a BAD idea. I will try and fix the algorithms tomorrow. If I redo my whole implementation over then this is all moot. 
